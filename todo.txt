o (DrugName, { (GeneName, PhenotypeName) }) -> Recommendation ; what's the limit on set size?
  - if it varies:
    - try cubric:
      X efficient subset join condition?
      - efficient where clause with subseteq: table.s subseteq i where input set i is LARGE (genome size large)?
        - cub_server runs in constant memory for "select count(*)" on table = 22*powerset of {1..20}, i = {1..100000}; 
          however, query is still slow (246.36s) and doesn't seem to be implementing any smart algorithm
          q_time             i={1...x} q_time/x  |table|  
          72.35              10000               23068673  
          246.36s            100000    405.91    23068673  
          605.41s            150000    247.76    23068673  
          1074.37s           200000    186.15    23068673 
        - can we index a set field? If so, does our query run faster?
          - NO, we can't index a set field:
            >> csql> alter table s1 add index s_idx(s);
               
               In the command from line 1,
               
               ERROR: Cannot define index on domain "set".
          - can we generate a unique index key (hash value) for our sets that can be used to reduce the number of candidate 
            sets s such that table.s subseteq i 
            - sounds similar (in particular "candidates") to subset-similarity join literature; so _probably_no_ (not 
              without access to database internals)
        - can we interface cubrid with grails...? If not...maybe django, but probably quit at this point...
          - troubles encountered when building https://github.com/CUBRID/hibernate-core from source and trying to replace 
            hibernate dependencies with custom built jars:
            missing class org.codehaus.groovy.grails.orm.hibernate.support.ClosureEventTriggeringInterceptor

        select count(*) from s1 where s1.s = {1,2,3};
        before index:
        rep q_time
        1   60.00s
        2   61.00
        3
        after index:
        rep q_time
        1
        2
        3

        'select count(*) from s1 where s1.s subseteq '"`perl -e 'print "{", (join ", ", (1..10000)), "}"'`"';'
        before index:
        rep q_time
        1
        2
        3
        after index:
        rep q_time
        1
        2
        3
        
        - create 2 simple tables of subsets of number 1...n, and see how fast 
          it joins
  - if it's within a handful:
    - stick with mysql and create a mapping from gene-names to subsets containing those genes
      - perform a set containment query in memory on candidates
o (GeneName, HaplotypeName, HaplotypeName) -> PhenotypeName ; any reliable source of this information?

- figure out how to obtain (GeneName, HaplotypeName, HaplotypeName) -> (GeneName, PhenotypeName) datasets from results 
  published in CPIC
  - how many haplotypes H are their typically for a given gene (since we need to store |H|^2 rows for a 
    given mapping)?
    - not too many
    - too many; figure out a new mapping ... -> (GeneName, PhenotypeName) that isn't so 
      space/time/management costly, but can still be used to query an input set (GeneName, HaplotypeName, HaplotypeName)
- test current code
  - get some test data
    - andrea's excel file
      - not very consistent in syntax (requires some tinkering to parse everything sanely), but somewhat consistent in data structure
      - cross references things on a by-drug basis
      - data present:
        drug_recommendation (only recommendation)
        gene_phenotype_drug_recommendation
        genotype_phenotype (for 1, pretty inconsistent formatting)
        genotype_drug_recommendation
      - data missing:
        haplotype_snps
        gene_haplotype_variant

    - PharmGKB
      - variation in syntax, but there is an underlying data structure; probably need to write slight variations on parsers for each drug page
      - cross references things on a by-drug basis
      - data present:
        drug_recommendation (only recommendation for some)
        gene_phenotype_drug_recommendation (for some)
        genotype_phenotype (for some; for single gene-drug pairs it's easy to extract [use ajax form on drug page], varies for multi-gene-drug pairs)
        genotype_drug_recommendation (for some)
        haplotype_snps (easy and consistent)
        gene_haplotype_variant (easy and consistent)
      - data missing:
  - use groovy unit test to setup the DB and run the different stages
    - test using different return types:
      - query/existing/engine
- TODO: make sure tables (intermediate result and schema tables) have indexes on "set columns", since joins will be happening on these columns
- make a function for running the whole pipeline from stage 1 (ideally, have some way to hook into the pipeline at various steps, and follow through to a final result)
- refactor Haplotype functions to insert intermediate results into a persistent tables instead of temporary input_* tables, with results identified by pipeline_job_id's
- start unit testing Haplotype functions
  - assert each job table in the pipeline
  - generate some comprehensive test data (use madeup stuff first that is understandable)
  - then use real data

[o] TODO: the input variants file doesn't tell us what snps occur on what chromosomes; handle this
  - TODO: handle it in the dumbest way by ignoring heterozygous calls, reporting this somehow 
  - TODO: handle it in a less dumb way (if the actual data requires it; test on real dataset 
    before doing this); ideas:
    [o] allow for at most 1 heterozygote call for a snp in a snp->gene_haplotype mapping
    - 'explode' the input variants into 2^(n-1) (where n = # of heterozygous calls) into possible 
      chromosomal variant calls, and only report intersecting results (determine at what stage(s) 
      to intersect) 

- TODO: design a web interface 
  - TODO: allow uploading of a (amibugous) variants file (a set of patients and their snps)
    - TODO: error check the input (e.g. make sure there aren't any duplicates that the pipeline 
      will silently fail with, in regards to old todo below)
      - old todo: fix issue where with selectWhereSetContains where a table with duplicate 
        variants doesn't get output correctly (select distinct on variants, then rejoin 
        mappingings with variants)
        TODO: think of an example where ambiguity happens, then figure out how to modify 
        selectWhereSetContains query to filter out gene's where ambiguity occurs 
        - TODO: code up solution (that doesn't modify selectWhereSetContains), as well as test 
          case that I made up, and make more test cases to make 
- TODO: record 'unique' haplotypes for genes
- TODO: record 'closely matched' haplotypes for genes
- TODO: test using a real dataset
  - TODO: make sure we didn't miss any requirements
- fix bug where for variants we only want to do tableA set is contained by tableB set (NOT either or); this failure identified by testGeneHaplotype
- fix bug where for phenotypes we only want to do tableA set is contained by tableB set (NOT either or); this failure identified by testGenePhenotype
- error out when a kwargs is not used to avoid using the wrong name for a dataset?

- make a summary report illustrating how data was obtained from mapping tables in the pipeline
  - split drug recommendations into phenotype / genotype based

- optimization: make drugRecommendations accept a dataSource as an argument (for generating Sql 
  instances), so it can pass an extra Sql instance to the geneHaplotypeToGenotype stage (for 
  groupedRowsToColumns)

- make a summary report file available for download  
  [o] split drug recommendations into phenotype / genotype based
  - the report file should illustrate where data came from at each stage
    - which variants map to a particular haplotype (from haplotype join variants)
    - which genotypes map to a particular phenotype (phenotypes join genotypes... but multiple genotype sets might map to the same phenotype.... blah)
    - which phenotypes/genotypes map to a particular drug recommendation (same issue as above; resolving the many side in a many-to-one relationship; we need to record the many when we record the one from which it came)
  - 2 approaches
    - straight up sql
      - pros: 
        - single query, so probably faster
        - works for arbitrary queries
        - easier to test (easy to make toy tables; ORM needs domains)
      - cons: 
        - (might) use more ram
        - need to query metadata information for tables
    - ORM
      - pros:
        - no sql
      - cons: 
        - multiple queries
        - limited to queries across foreign key relationships

- straight up sql
  - perform mega join query
    - one for phenotype
    - one for genotype
    - kinda did this, minus querying table metadata (it's hardcoded)
      - since we're only using the mapping tables:
        - this doesn't necessarily correspond to data that was input (IF they're using more input than just variants) since 
        - some data won't be repeated as I might expect (for good or bad, depends on what they expect) (e.g. genotype *1/*1 gets its haplotype 
          shown only once due to join condition, but could be remedied by joining against input variants)
        [o] next step we want to do is "collapsing" consecutive rows with blanks, for e.g. in samplejob_noduplicate_phenotype.txt we have:

        patient2   | 2                      | g1        | heterozygote      | *1              | *2              | _              | _      | _
        _          | _                      | _         | _                 | _               | _               | _              | _      | _
        _          | _                      | _         | _                 | _               | _               | *2             | rs3    | C
        _          | _                      | _         | _                 | _               | _               | *2             | rs4    | T

        [o] after collapsing, we want:

        patient2   | 2                      | g1        | heterozygote      | *1              | *2              | *2             | rs3    | C
        _          | _                      | _         | _                 | _               | _               | *2             | rs4    | T

  ~ create a function that wraps the row results and eliminates duplicity that we don't want
    - in Sql module, create a function for getting table primary key metadata: [ table : [primary key] ]
