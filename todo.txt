o (DrugName, { (GeneName, PhenotypeName) }) -> Recommendation ; what's the limit on set size?
  - if it varies:
    - try cubric:
      X efficient subset join condition?
      - efficient where clause with subseteq: table.s subseteq i where input set i is LARGE (genome size large)?
        - cub_server runs in constant memory for "select count(*)" on table = 22*powerset of {1..20}, i = {1..100000}; 
          however, query is still slow (246.36s) and doesn't seem to be implementing any smart algorithm
          q_time             i={1...x} q_time/x  |table|  
          72.35              10000               23068673  
          246.36s            100000    405.91    23068673  
          605.41s            150000    247.76    23068673  
          1074.37s           200000    186.15    23068673 
        - can we index a set field? If so, does our query run faster?
          - NO, we can't index a set field:
            >> csql> alter table s1 add index s_idx(s);
               
               In the command from line 1,
               
               ERROR: Cannot define index on domain "set".
          - can we generate a unique index key (hash value) for our sets that can be used to reduce the number of candidate 
            sets s such that table.s subseteq i 
            - sounds similar (in particular "candidates") to subset-similarity join literature; so _probably_no_ (not 
              without access to database internals)
        - can we interface cubrid with grails...? If not...maybe django, but probably quit at this point...
          - troubles encountered when building https://github.com/CUBRID/hibernate-core from source and trying to replace 
            hibernate dependencies with custom built jars:
            missing class org.codehaus.groovy.grails.orm.hibernate.support.ClosureEventTriggeringInterceptor

        select count(*) from s1 where s1.s = {1,2,3};
        before index:
        rep q_time
        1   60.00s
        2   61.00
        3
        after index:
        rep q_time
        1
        2
        3

        'select count(*) from s1 where s1.s subseteq '"`perl -e 'print "{", (join ", ", (1..10000)), "}"'`"';'
        before index:
        rep q_time
        1
        2
        3
        after index:
        rep q_time
        1
        2
        3
        
        - create 2 simple tables of subsets of number 1...n, and see how fast 
          it joins
  - if it's within a handful:
    - stick with mysql and create a mapping from gene-names to subsets containing those genes
      - perform a set containment query in memory on candidates
o (GeneName, HaplotypeName, HaplotypeName) -> PhenotypeName ; any reliable source of this information?

- figure out how to obtain (GeneName, HaplotypeName, HaplotypeName) -> (GeneName, PhenotypeName) datasets from results 
  published in CPIC
  - how many haplotypes H are their typically for a given gene (since we need to store |H|^2 rows for a 
    given mapping)?
    - not too many
    - too many; figure out a new mapping ... -> (GeneName, PhenotypeName) that isn't so 
      space/time/management costly, but can still be used to query an input set (GeneName, HaplotypeName, HaplotypeName)
- test current code
  - get some test data
    - andrea's excel file
      - not very consistent in syntax (requires some tinkering to parse everything sanely), but somewhat consistent in data structure
      - cross references things on a by-drug basis
      - data present:
        drug_recommendation (only recommendation)
        gene_phenotype_drug_recommendation
        genotype_phenotype (for 1, pretty inconsistent formatting)
        genotype_drug_recommendation
      - data missing:
        haplotype_snps
        gene_haplotype_variant

    - PharmGKB
      - variation in syntax, but there is an underlying data structure; probably need to write slight variations on parsers for each drug page
      - cross references things on a by-drug basis
      - data present:
        drug_recommendation (only recommendation for some)
        gene_phenotype_drug_recommendation (for some)
        genotype_phenotype (for some; for single gene-drug pairs it's easy to extract [use ajax form on drug page], varies for multi-gene-drug pairs)
        genotype_drug_recommendation (for some)
        haplotype_snps (easy and consistent)
        gene_haplotype_variant (easy and consistent)
      - data missing:
  - use groovy unit test to setup the DB and run the different stages
    - test using different return types:
      - query/existing/engine
- TODO: make sure tables (intermediate result and schema tables) have indexes on "set columns", since joins will be happening on these columns
- make a function for running the whole pipeline from stage 1 (ideally, have some way to hook into the pipeline at various steps, and follow through to a final result)
- refactor Haplotype functions to insert intermediate results into a persistent tables instead of temporary input_* tables, with results identified by pipeline_job_id's
- start unit testing Haplotype functions
  - assert each job table in the pipeline
  - generate some comprehensive test data (use madeup stuff first that is understandable)
  - then use real data

[o] TODO: the input variants file doesn't tell us what snps occur on what chromosomes; handle this
  - TODO: handle it in the dumbest way by ignoring heterozygous calls, reporting this somehow 
  - TODO: handle it in a less dumb way (if the actual data requires it; test on real dataset 
    before doing this); ideas:
    [o] allow for at most 1 heterozygote call for a snp in a snp->gene_haplotype mapping
    - 'explode' the input variants into 2^(n-1) (where n = # of heterozygous calls) into possible 
      chromosomal variant calls, and only report intersecting results (determine at what stage(s) 
      to intersect) 

- TODO: design a web interface 
  - TODO: allow uploading of a (amibugous) variants file (a set of patients and their snps)
    - TODO: error check the input (e.g. make sure there aren't any duplicates that the pipeline 
      will silently fail with, in regards to old todo below)
      - old todo: fix issue where with selectWhereSetContains where a table with duplicate 
        variants doesn't get output correctly (select distinct on variants, then rejoin 
        mappingings with variants)
        TODO: think of an example where ambiguity happens, then figure out how to modify 
        selectWhereSetContains query to filter out gene's where ambiguity occurs 
        - TODO: code up solution (that doesn't modify selectWhereSetContains), as well as test 
          case that I made up, and make more test cases to make 
- TODO: record 'unique' haplotypes for genes
- TODO: record 'closely matched' haplotypes for genes
- TODO: test using a real dataset
  - TODO: make sure we didn't miss any requirements
- fix bug where for variants we only want to do tableA set is contained by tableB set (NOT either or); this failure identified by testGeneHaplotype
- fix bug where for phenotypes we only want to do tableA set is contained by tableB set (NOT either or); this failure identified by testGenePhenotype
- error out when a kwargs is not used to avoid using the wrong name for a dataset?

- make a summary report illustrating how data was obtained from mapping tables in the pipeline
  - split drug recommendations into phenotype / genotype based

- optimization: make drugRecommendations accept a dataSource as an argument (for generating Sql 
  instances), so it can pass an extra Sql instance to the geneHaplotypeToGenotype stage (for 
  groupedRowsToColumns)

- make a summary report file available for download  
  [o] split drug recommendations into phenotype / genotype based
  - the report file should illustrate where data came from at each stage
    - which variants map to a particular haplotype (from haplotype join variants)
    - which genotypes map to a particular phenotype (phenotypes join genotypes... but multiple genotype sets might map to the same phenotype.... blah)
    - which phenotypes/genotypes map to a particular drug recommendation (same issue as above; resolving the many side in a many-to-one relationship; we need to record the many when we record the one from which it came)
  - 2 approaches
    - straight up sql
      - pros: 
        - single query, so probably faster
        - works for arbitrary queries
        - easier to test (easy to make toy tables; ORM needs domains)
      - cons: 
        - (might) use more ram
        - need to query metadata information for tables
    - ORM
      - pros:
        - no sql
      - cons: 
        - multiple queries
        - limited to queries across foreign key relationships

- straight up sql
  [o] perform mega join query
    - one for phenotype
    - one for genotype
    - kinda did this, minus querying table metadata (it's hardcoded)
      - since we're only using the mapping tables:
        - this doesn't necessarily correspond to data that was input (IF they're using more input than just variants) since 
        - some data won't be repeated as I might expect (for good or bad, depends on what they expect) (e.g. genotype *1/*1 gets its haplotype 
          shown only once due to join condition, but could be remedied by joining against input variants)
        [o] next step we want to do is "collapsing" consecutive rows with blanks, for e.g. in samplejob_noduplicate_phenotype.txt we have:

        patient2   | 2                      | g1        | heterozygote      | *1              | *2              | _              | _      | _
        _          | _                      | _         | _                 | _               | _               | _              | _      | _
        _          | _                      | _         | _                 | _               | _               | *2             | rs3    | C
        _          | _                      | _         | _                 | _               | _               | *2             | rs4    | T

        [o] after collapsing, we want:

        patient2   | 2                      | g1        | heterozygote      | *1              | *2              | *2             | rs3    | C
        _          | _                      | _         | _                 | _               | _               | *2             | rs4    | T

  [o] create a function that wraps the row results and eliminates duplicity that we don't want
    [o] in Sql module, create a function for getting table primary key metadata: [ table : [primary key] ]

- make sure dependency graph stuff works for 2 base nodes (i know level() won't work =z)
- fix broken Report tests due to Row refactoring, then go make wui work with new levels
- join drug_recommendation stuff
- make Report functions know what default table names are

- report output is incorrect, since it joins only against mapping tables, it will output all the 
  many's in a one-to-many join instead of restricting it to just the many that we saw in the 
  pipeline table.
- report should only prevent "repeated data" for the same patient; different patient should have variant data "repeated"
- only use job_patient_* tables in report select, and remove duplicates by THEIR ids
- remote duplicates isn't going to work since we can't handle duplicate column names properly (the rows returned only have one 'id')
- fix duplicate groupings such that:
  - we don't repeat a haplotype for the same patient
    - job_patient_gene_haplotype dupkey should be (job_id, patient_id, gene_name, haplotype_name)
  - we repeat variants for the same patient but a different haplotype (but we don't repeat variants with the same allele and snp_id but only a different zygosity)
    - job_patient_variant dupkey should be (job_id, patient_id, gene_name, haplotype_name, allele, snp_id)
- add alterative header (do this via toDSV... i think)
- why aren't phenotype rows collapsing?

- figure out why stuff isn't condensing
- it's because we have multiple genotype's (g1 *1/*2, *1/*3) mapping to the same phenotype (heterozygote) in gene_phenotype, but since we do left joins, we end up keeping the row
  - we can get rid of the non-existent genotype by doing "join job_patient_genotype" instead of "left join", but this means that if the user manually added a phenotype 
    for which a genotype wasn't found, then that drug recommendation wouldn't be reported (confirmed)
  - perhaps we can get rid of them through the where clause
    - what do the bad rows look like? can we distinguish them from rows where a job_patient_phenotype was added
      - they are groups of patient rows where one row has a phenotype with a genotype, and the other have the same phenotype but no matching genotype
  - perhaps we can change the collapsing strategy
  - perhaps we can consider them as duplicates; (job_id, patient_id, phenotype_name); no it'll arbitrarily remove rows (might leave the null one)
  - root of the problem: trying to resolve the many in a many-to-one mapping using just the one...
    - solutions: 
      - make it one-to-one (involves changing a bunch of stuff)
      - custom collapsing strategy
        - collapse rows with the same phenotype if there is exactly one row with a genotype for that phenotype
        - can't we just remove the null-valued entries...?
          - use a debugger to figure out why this isn't working
        - duplicate removal ensures that rows with null's for their primary key will get removed, which ensures that there will only be one row for all the failed 
          genotype_p

- ask andrea about tools for disambiguating which alleles in heterozygous snps 
  occur on the same physical chromosome

- create sample using real data
  - use CYP2C19 data from aaron
    - there is no overlap between snp_id's in CYP2C19_haplotype_matrix.txt and snp_id's in sample variants file from lars
    [o] create a script for converting gene_haplotype matrix into gene_haplotype 
      table format
    - find a gene whose snp_id's overlap with our sample variant file
      - none of the snp_id's in the sample variants are found in genes that have drug recommendations on pharmgkb
    - gather all gene_haplotype data and determine a list of snp_id's that have drug recommendations on pharmgkb
    [o] try out scrapy for gathering gene_haplotype data
      - is it possible to use scrapy on local html files instead of always downloading stuff (i.e. can we 
        cache stuff?)
        - yes, "wget -r" it then run a local web server
- create a web crawler to extract pharmgkb data
  - crawl out from cpicGeneDrugPairs to the gene pages
    [o] extract gene-haplotype matrices from gene pages
      - gather a list of snp_ids for each gene, and ask lars for genotyping data sample file that uses these snp_ids (it has to be all of them for a 
        gene...otherwise we need to select a subset of snps to care about for each gene)

- other datasets still needing extraction:
  1. genotype -> drug recommendation
  2. phenotype -> drug recommendation
  3. genotype -> phenotype 
  - 1. 2. and 3. are presented in inconsistent ways making it difficult to extract automatically
    - (TODO: check that ajax form that pops up and figure out how to use it to extract genotype -> drug recommendation / phenotype)
  - extract json urls to query using scrapy (grab it from things like Y.Guidelines.popPickers('#edg981483939','981483939'); ) (NOTE: 981483939 is the 
    "annotationId")
    - json urls:
      - haplotype names / internal haplotype ids:
        http://www.pharmgkb.org/views/ajaxGuidelinePickerData.action?annotationId=827848453
      - genotype -> * mappings (i.e. -> phenotype / and drug recommendation):
        http://www.pharmgkb.org/views/alleleGuidelines.action?allele1=PA165987830&allele2=--&location=HLA-B&annotationId=827848453
        http://www.pharmgkb.org/views/alleleGuidelines.action?allele1=PA165987830&allele2=PA165987830&location=HLA-B&annotationId=827848453
      - for genes with significantly many haplotypes (e.g. CYP2D6 on http://www.pharmgkb.org/gene/PA128), clearly there are certain phenotypes associated 
        with each allele (e.g. non-functional, functional, reduced function) determinable from the "Phenotype (Genotype)" (e.g. An individual carrying 
        only non-functional alleles) when the same allele is entered.
    - TODO: the drug recommendations given for GenotypeSpider are missing drug_name... i'm not sure if its really useful then....
      WRONG: the "Look up your guideline" dialogs are given PER-DRUG

- check for genes missing from any of the files
  - why are they missing?
  - add checks for empty stuff instead of iterating over an empty list silently
[o] the "Look up your guideline" dialogs are given PER-DRUG
  - need to extract drug_name and pass it to GenotypeSpider
- check genes in genotype_phenotype.csv for non-descriptive phenotypes that could be obtained from alternate fields (by 
  adding to phenotype_exceptions)
- missing drug_recommendation's for:
  - http://www.pharmgkb.org/gene/PA134865839#tabview=tab0&subtab=31 : doesn't use haplotypes but instead uses a single 'genotype' field
    e.g. 

    (equivalent of GeneHaplotypeSpider)
    http://www.pharmgkb.org/views/ajaxGuidelinePickerData.action?annotationId=827921472
    -> {"results":[{"alleles":["CC","TC","TT"],"rsid":"rs4149056"}]}

    (equivalent of GenotypeSpider)
    http://www.pharmgkb.org/views/alleleGuidelines.action?allele1=TC&location=rs4149056&annotationId=827921472
    -> 
    Phenotype (Genotype)
    Intermediate activity

    Implications
    Intermediate myopathy risk

    Recommendations (Strength: Strong)
    FDA recommends against 80 mg. Consider a lower dose; if suboptimal efficacy, consider an alternative statin.

    At the time of the development of this recommendation, there are no data available on the possible role of SLCO1B1 in simvastatin-induced myopathies in pediatric patient populations; however, there is no reason to suspect that SLCO1B1 variant alleles would affect simvastatin hepatic uptake differently in children compared to adults. Please see below for full details of these guidelines, with supporting evidence and disclaimers.

  - when reading the gene-haplotype matrix in parse_haplotypes_table, record the table in the GeneSpider, then pass it along and use it when parsing inside GenotypeSpider
    - use mixin patterns to share code for SnpGenotypeSpider

- start inserting data from scraping
  - need to pre-process csv files into a readily loadable format and maintain id mappings for autoincrement fields (e.g. autoincrement)
    - pre-process into generator, and pass the generator to some load_into_table function
  - use oursql to use prepared statements (via executemany), as well as obtain lastrowid's
  - load_dsv.py:
    - given a list of dsv files, insert the files into their respective tables (files are named <table_name>.<extension>), maintaining foreign key constraints
    - for autoincrement tables T referenced by other tables R_i, require a set of keys K_i in both T and R_i that can be used to resolve generated ids from T to use 
      in R_i
    - to avoid overcomplicating the script, insert files in the order they are provided (the fancy way would be to generate a dependency graph based on foreign key 
      relationships...)
- mysql_string_type.py: 
  - gather statistics for other fields (max length * 2) and make sure within limits (65,535)
    - for indexed fields, only return a 'length' suggestion
    - for non-indexed fields, map length of field to string type:
      see http://dev.mysql.com/doc/refman/5.0/en/storage-requirements.html ( Storage Requirements for String Types )
- change varchar fields to text fields where appropriate (e.g. drug_recommendation.recommendation)
  - figure where to do this by simply looking at errors spewed out by mysql after statistics gathering

- make a normalization wrapper for certain fields (phenotype_name) in scrapy items to lower case the string, and remove trailing 
  periods
- for genotype_phenotype fields with collisions, merge descriptions

- load data
- figure out how to represent the "snp's we care about (aaron)" when determining a gene haplotype
- make drug recommendation's viewable (with annotated links to view more info on the drug recommendation)

CYPD26:
133 rows (haplotypes)
151 columns (snp_ids)

- remove job_patient_variant_chromosome (i.e. 'ambiguous variants')

- make sure the report still works (i.e. only reports variants found in the input)
- make more test cases for testing variants
  - snps are a subset of a haplotype, but one snp is unique (unknown haplotype)
- loadtest
  - figure out how best to time queries / detect slow running queries (slow log, somehow add time start / stop to 
    rules, or use a profiling tool)
  - add indexes
    - for selectWhereSetContains, determine how groupby clause is affected by indexes
  - stats:
    - samples per file ~ 22
    - variants per sample ~ 23

- remove patient links, and make it show up as sample id
- figure out why variantToGeneHaplotype isn't using variantGene

redo crappy query / optimization with variant_gene table, see if it makes things better
add more outer query crap to see if it goes slow
optimize more
once it runs faster, then implement it

fix test data so testGeneHaplotype returns results then see if optimization is sufficient

fix test data to remove duplicate haplotypes

fix test data so that we can scale up # of variants per sample without overscaling other things (variants per 
haplotype, haplotypes per gene)

concern: _job_patient_variant_gene table won't scale since it get filled with job_patient_variant * (# distinct gene, haplotype, snp)
- try using a view and see if it uses indexes (i doubt it)

implement selectWhereSetContains optimization:
- insert counts_table records into a supplied table
- after we use the helper tables in variantToGeneHaplotype, delete records with that job_id (we don't need them anymore)
- figure out why s.gene_name2 not in (...) makes the query suck, and how to make it go faster / use a different query

- large deletions are slow as hell...use a temporary table and just drop it
  - can't do that, since selectWhereSetContains uses the temp table twice in a single query (mysql limitation)

- change s.gene_name2 not in query to:
        select gene_name
        from job_patient_variant v
        join gene_haplotype_variant using (snp_id)
        where 
        v.zygosity     = 'het' and
        v.job_id     = 1 and
        v.patient_id = s.patient_id and
		v.physical_chromosome = s.physical_chromosome
        group by gene_name
        having count(*) > 1
and see if the index works its magic... really need to try with lots of heterozygous snps though...

figure out why defaults-file doesn't seem to be getting read... log file change

most other queries are basic joins / more selectWhereSetContains stuff....

---
run aaron's PGX file

- bug: some samples had only 1 haplotype identified; possible cause: there is a bug where even if a 
  haplotype can be called unambiguously with a set of hom variants, there are > 1 het variants that get 
  used anyways 
  - but regardless of hom variants, if there are multiple het variants, we can't unambiguously say what 
    haplotype we have (it is an error to only consider 1 het variant)

- add a job_patient_novel_haplotype table that records novel haplotype's, and populate it during variantToGeneHaplotype

- bug: figure out why some unique haplotypes have a null physical chromosome
  - it's because we record some variants that have '' as the allele as having a null physical 
    chromsome

- add het_combo / het_combos to all job_patient tables
- bug: when we add het_combo / het_combos to tables, it messes up populating various tables from 
  input files; probably just disable populating from anywhere except variant

- bug: selectWhereSetContains needs to group by het_combo
- bug: PipelineTest's need to add het_combo / het_combos to relavent tables
  - variantsToHaplotypes should never get an empty list of variants
- make old tests incorporate het_combo / het_combos
- create new tests to test new behaviour:
  - disambiguation of heterozygote variants
    - 1 het
      - 2 known haplotypes
      - 1 known, 1 novel
    - > 1 het
      - 2 known haplotypes, 1 combination
      - 2 known haplotypes, 2 combinations
      - 1 known, 1 novel, 1 combination
      - 1 known, 1 novel, 2 combinations
      - 2 known haplotypes OR 1 known 1 novel, 1 combination each
      - 2 known haplotypes, 2 combinations OR 1 known 1 novel, 1 combination
      - 2 novel
      - 1 known, 1 novel OR 2 novel
  - test inside Pipeline 
    - 1 het
      - 2 known haplotypes
      - 1 known, 1 novel
    - > 1 het
      - 2 known haplotypes, 1 combination
      - 1 known, 1 novel, 1 combination
      - 2 known haplotypes, 2 combinations
      - 1 known, 1 novel, 2 combinations
      - 2 known haplotypes OR 1 known 1 novel, 1 combination each
